{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier - Before SMOTEENN:\n",
      "Accuracy: 0.7739336492890996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      1549\n",
      "           1       0.57      0.60      0.59       561\n",
      "\n",
      "    accuracy                           0.77      2110\n",
      "   macro avg       0.71      0.72      0.72      2110\n",
      "weighted avg       0.78      0.77      0.78      2110\n",
      "\n",
      "\n",
      "Decision Tree Classifier - After SMOTEENN:\n",
      "Accuracy: 0.9217210990150337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       865\n",
      "           1       0.93      0.93      0.93      1064\n",
      "\n",
      "    accuracy                           0.92      1929\n",
      "   macro avg       0.92      0.92      0.92      1929\n",
      "weighted avg       0.92      0.92      0.92      1929\n",
      "\n",
      "\n",
      "Random Forest Classifier - Before SMOTEENN:\n",
      "Accuracy: 0.7895734597156399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1549\n",
      "           1       0.65      0.44      0.53       561\n",
      "\n",
      "    accuracy                           0.79      2110\n",
      "   macro avg       0.74      0.68      0.70      2110\n",
      "weighted avg       0.78      0.79      0.78      2110\n",
      "\n",
      "\n",
      "Random Forest Classifier - After SMOTEENN:\n",
      "Accuracy: 0.9232763089683774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       865\n",
      "           1       0.93      0.93      0.93      1064\n",
      "\n",
      "    accuracy                           0.92      1929\n",
      "   macro avg       0.92      0.92      0.92      1929\n",
      "weighted avg       0.92      0.92      0.92      1929\n",
      "\n",
      "\n",
      "Logistic Regression - Before SMOTEENN:\n",
      "Accuracy: 0.790521327014218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1549\n",
      "           1       0.64      0.48      0.55       561\n",
      "\n",
      "    accuracy                           0.79      2110\n",
      "   macro avg       0.73      0.69      0.71      2110\n",
      "weighted avg       0.78      0.79      0.78      2110\n",
      "\n",
      "\n",
      "Logistic Regression - After SMOTEENN:\n",
      "Accuracy: 0.911353032659409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       865\n",
      "           1       0.91      0.93      0.92      1064\n",
      "\n",
      "    accuracy                           0.91      1929\n",
      "   macro avg       0.91      0.91      0.91      1929\n",
      "weighted avg       0.91      0.91      0.91      1929\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classifier - Before SMOTEENN:\n",
      "Accuracy: 0.7843601895734598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      1549\n",
      "           1       0.61      0.54      0.57       561\n",
      "\n",
      "    accuracy                           0.78      2110\n",
      "   macro avg       0.72      0.71      0.71      2110\n",
      "weighted avg       0.78      0.78      0.78      2110\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classifier - After SMOTEENN:\n",
      "Accuracy: 0.9004665629860031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       865\n",
      "           1       0.87      0.96      0.91      1064\n",
      "\n",
      "    accuracy                           0.90      1929\n",
      "   macro avg       0.91      0.89      0.90      1929\n",
      "weighted avg       0.90      0.90      0.90      1929\n",
      "\n",
      "\n",
      "All models and scaler saved to: /home/shoaib/Code/Churn_pred/app/models\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "project_root = '/home/shoaib/Code/Churn_pred' # Get project root directory\n",
    "data_path = os.path.join(project_root, 'app', 'data', 'Cleaned_Telecom_Dataset_New.csv')\n",
    "models_dir = os.path.join(project_root, 'app', 'models')\n",
    "\n",
    "# Reading csv\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop('Unnamed: 0', axis=1)  # Assuming 'Unnamed: 0' is irrelevant\n",
    "\n",
    "# Feature Selection (Do this before scaling)\n",
    "X = df.drop('Churn', axis=1) \n",
    "y = df['Churn']\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X) # Fit on the entire dataset\n",
    "\n",
    "# *** SAVE THE FITTED SCALER ***\n",
    "scaler_path = os.path.join(models_dir, 'scaler.pkl')\n",
    "pickle.dump(scaler, open(scaler_path, 'wb')) \n",
    "\n",
    "# *** INITIAL Train Test Split - BEFORE SMOTEENN ***\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "# --- SMOTEENN (applied to the ENTIRE dataset) ---\n",
    "sm = SMOTEENN(smote=SMOTE(random_state=42))\n",
    "X_resampled, y_resampled = sm.fit_resample(X, y) # Fit on scaled data\n",
    "\n",
    "# Train Test Split AFTER SMOTEENN \n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42) \n",
    "\n",
    "# --- Decision Tree Classifier ---\n",
    "# Before SMOTEENN - Use initial split data (X_train, y_train, X_test, y_test)\n",
    "model_dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=6, min_samples_leaf=8)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "print(\"\\nDecision Tree Classifier - Before SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_dt.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "# dt_model_path = os.path.join(models_dir, 'decision_tree_model.pkl')\n",
    "# pickle.dump(model_dt, open(dt_model_path, 'wb')) # Save the model\n",
    "\n",
    "# After SMOTEENN - Use data from split after SMOTEENN (Xr_train, yr_train, Xr_test, yr_test)\n",
    "model_dt_smote = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=6, min_samples_leaf=8)\n",
    "model_dt_smote.fit(Xr_train, yr_train)\n",
    "yr_pred_dt = model_dt_smote.predict(Xr_test)\n",
    "print(\"\\nDecision Tree Classifier - After SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_dt_smote.score(Xr_test, yr_test)}\")\n",
    "print(classification_report(yr_test, yr_pred_dt))\n",
    "dt_smote_model_path = os.path.join(models_dir, 'decision_tree_smote_model.pkl')\n",
    "pickle.dump(model_dt_smote, open(dt_smote_model_path, 'wb')) # Save the model\n",
    "\n",
    "# --- Random Forest Classifier ---\n",
    "# Before SMOTEENN - Use initial split data \n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=6, min_samples_leaf=8)\n",
    "model_rf.fit(X_train, y_train) \n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print(\"\\nRandom Forest Classifier - Before SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_rf.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "# rf_model_path = os.path.join(models_dir, 'random_forest_model.pkl')\n",
    "# pickle.dump(model_rf, open(rf_model_path, 'wb')) # Save the model\n",
    "\n",
    "# After SMOTEENN - Use data from split after SMOTEENN\n",
    "model_rf_smote = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=6, min_samples_leaf=8)\n",
    "model_rf_smote.fit(Xr_train, yr_train)\n",
    "yr_pred_rf = model_rf_smote.predict(Xr_test)\n",
    "print(\"\\nRandom Forest Classifier - After SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_rf_smote.score(Xr_test, yr_test)}\")\n",
    "print(classification_report(yr_test, yr_pred_rf))\n",
    "rf_smote_model_path = os.path.join(models_dir, 'random_forest_smote_model.pkl')\n",
    "pickle.dump(model_rf_smote, open(rf_smote_model_path, 'wb')) # Save the model\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "# Before SMOTEENN - Use initial split data\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=10000, solver='liblinear')\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "print(\"\\nLogistic Regression - Before SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_lr.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "# lr_model_path = os.path.join(models_dir, 'logistic_regression_model.pkl')\n",
    "# pickle.dump(model_lr, open(lr_model_path, 'wb')) # Save the model\n",
    "\n",
    "# After SMOTEENN - Use data from split after SMOTEENN\n",
    "model_lr_smote = LogisticRegression(random_state=42, max_iter=10000, solver='liblinear')\n",
    "model_lr_smote.fit(Xr_train, yr_train)\n",
    "yr_pred_lr = model_lr_smote.predict(Xr_test)\n",
    "print(\"\\nLogistic Regression - After SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_lr_smote.score(Xr_test, yr_test)}\")\n",
    "print(classification_report(yr_test, yr_pred_lr))\n",
    "lr_smote_model_path = os.path.join(models_dir, 'logistic_regression_smote_model.pkl')\n",
    "pickle.dump(model_lr_smote, open(lr_smote_model_path, 'wb')) # Save the model\n",
    "\n",
    "# --- K-Nearest Neighbors Classifier ---\n",
    "# Before SMOTEENN - Use initial split data\n",
    "model_knn = KNeighborsClassifier(n_neighbors=30)\n",
    "model_knn.fit(X_train, y_train)\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "print(\"\\nK-Nearest Neighbors Classifier - Before SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_knn.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "knn_model_path = os.path.join(models_dir, 'knn_model.pkl')\n",
    "pickle.dump(model_knn, open(knn_model_path, 'wb')) # Save the model\n",
    "\n",
    "# After SMOTEENN - Use data from split after SMOTEENN\n",
    "model_knn_smote = KNeighborsClassifier(n_neighbors=30)\n",
    "model_knn_smote.fit(Xr_train, yr_train)\n",
    "yr_pred_knn = model_knn_smote.predict(Xr_test)\n",
    "print(\"\\nK-Nearest Neighbors Classifier - After SMOTEENN:\")\n",
    "print(f\"Accuracy: {model_knn_smote.score(Xr_test, yr_test)}\")\n",
    "print(classification_report(yr_test, yr_pred_knn))\n",
    "knn_smote_model_path = os.path.join(models_dir, 'knn_smote_model.pkl')\n",
    "pickle.dump(model_knn_smote, open(knn_smote_model_path, 'wb')) # Save the model\n",
    "\n",
    "print(f\"\\nAll models and scaler saved to: {models_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telecom-flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
